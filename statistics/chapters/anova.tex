\chapter{Analysis of Variance}

\section{ANOVA Fundamentals}
\begin{itemize}
  \item \ddd{Analysis of variance (ANOVA)}: a collection of statistical models and their associated estimates, based on the law of total variance, aimed at determining the effects of \xxx{discrete independent variables (IV, \(X_n\))} on a \yyy{continuous dependent variable (DV, \(Y\))}.
    \begin{itemize}
      \item \ddd{Law of total variance}: if \xxx{\(X\)} and \yyy{\(y\)} are random variables on the same probability space, and the variance of \yyy{\(Y\)} is finite, then
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \var(\yyy{Y}) = E[\var(\yyy{Y}~|\,\xxx{X})] + \var(E[\yyy{Y}~|\,\xxx{X}])
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \end{itemize}
  \item \ddd{Basic outline for setting up an ANOVA\@}:
    \begin{enumerate}
      \item Identify the \xxx{independent} and \yyy{dependent} variables.
      \begin{itemize}
        \item Sometimes termed the \xxx{explained} and \yyy{unexplained} components of variability.
      \end{itemize}
      \item Determine \emph{applicability of ANOVA} to the experimental design in question.
        \begin{itemize}
          \item Needs categorical factors, with two or more levels within each factor.
            \begin{itemize}
              \item \ddd{Factors \(\lambda\)}: the ``dimensions'' of the \xxx{IVs}.
              \item \ddd{Levels \(\epsilon\)}: the specific groups (means) or manipulations within each factor.
            \end{itemize}
          \item Generally used to test differences among at least three levels, as \(t\)-tests and correlations are used for two.
        \end{itemize}
      \item Create a table of factors and levels (if possible; when factors > 2, then it's not used).
      \item Perform computation and \emph{interpret results}.
        \begin{itemize}
          \item \ddd{Main effect}: when one factor primarily influences the \yyy{dependent} variable.
          \item \ddd{Interactions}: the effect of one factor depends on the levels or another factor.
          \item \ddd{Intercept}: when the average of \yyy{dependent} variable is different from zero.
        \end{itemize}
    \end{enumerate}

  \subsection{Study Designs}
  \begin{itemize}
    \item \ddd{One-way ANOVA}: used for testing differences of two or more levels with \emph{one factor}.
    \item \ddd{Factorial ANOVA}: used when there is \emph{more than one} factor, e.g., \hyperref[Subsection: Two-Way ANOVA]{\dlink{two-way ANOVA}}.
    \item \ddd{Repeated measures ANOVA}: used when the same subjects are used for each factor, e.g., in longitudinal studies.
    \item \ddd{Multivariate ANOVA}: when there is more than one \yyy{dependent} variable.
    \item \ddd{Balanced}: the same number of data points (sample size) in each treatment.
      \begin{itemize}
        \item \ddd{Unbalanced}: different number of data points; often increases complexity and reduces both robustness and statistical power. 
      \end{itemize}
  \end{itemize}
    
  \subsection{Classes of Models}
  \begin{itemize}
    \item \ddd{Fixed-effects (class I)}: when the number of levels of a factor is fixed, i.e., there are \emph{discrete}, and often \emph{static}, groups within each factor.
      \begin{itemize}
        \item Allows estimation of the ranges of \yyy{dependent} variable values that treatments would generate in the population.
      \end{itemize}
    \item \ddd{Random-effects (class II)}: when the levels within a factor are random in the population, i.e., there are \emph{random}, and often \emph{variable}, groups within each factor.
      \begin{itemize}
        \item Some levels can be discretized into discrete, fixed levels, but many cannot.
      \end{itemize}
    \item \ddd{Mixed-effects (class III)}: a mixture of \emph{fixed and random} effects, i.e., a factorial ANOVA wherein at least one factor is fixed and at least one other is random.
    \item Note: defining fixed and random effects has proven to be elusive, with non-standardized definitions of each often causing confusion.
  \end{itemize}

  \subsection{Assumptions of ANOVA}
  \begin{itemize}
    \item The most common approaches use \emph{linear models} that relate groups and controls to the \xxx{independent} variables on the \yyy{dependent} variables, which assume:
      \begin{itemize}
        \item \ddd{Independence}: the data are sampled independently of each other in the population to which you want to generalize.
        \item \ddd{Normality}: the residuals (unexplained variance) are roughly Gaussian.
        \item \ddd{Homoscedasticity}: the variance of the data in groups should be roughly equal.
      \end{itemize}
    \item Many problems that do not satisfy the assumptions of the ANOVA can often be transformed to satisfy them. 
      \begin{itemize}
        \item E.g., the Kruskal-Wallis test can be used on rank-transformed data, and unit-treatment additivity can be applied in some cases.
        \item However, many uses of ANOVA are generally robust enough to deal with violations; transformation can often be inefficient, leading more work than use.
      \end{itemize}
  \end{itemize}
\end{itemize}

\section{ANOVA Methods}
\begin{itemize}
  \item In a generic sense, ANOVA is used to compare the \(H_\nil\) to an \(H_a\);
    \begin{itemize}
      \item \ttt{\(H_\nil\)}: the \ttt{null hypothesis}, which states the \emph{means of all groups} \(\mu_k\) are statistically \ttt{indistinguishable}, i.e,
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \ttt{H_\nil} : \mu_1 = \mu_2 = \mu_{\ldots} = \mu_k
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \item \fff{\(H_a\)}: the \fff{alternative hypothesis}, which is true when \emph{at least one group mean} is statistically \fff{distinguishable} from another group mean, i.e.,
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \fff{H_a} = \mu_i \neq \mu_j
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \end{itemize}
  \item Finding out what the difference between the group means, if there is one, requires \hyperref[Subsection: Post Hoc Comparisons]{\dlink{post-hoc comparisons}}.

  \subsection{Sum of Squares}
  \begin{itemize}
    \item The first step in ANOVA is to compute and interpret the \hyperref[Subsection: Measures of Dispersion]{\ulink{measure of dispersion}} between groups, within groups, and in total, using \hyperref[Subsection: Measures of Dispersion]{\ulink{variance}} (\ddd{sum of squares}), i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \sigma^2 = \ddd{SS} = \sum_{i = 1}^{n}(x_i-\bar{x})^2
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
      \item Note: this is sample variance, so the divisor (\hyperref[Subsection: Degrees of Freedom]{\ulink{degree of freedom \(\nu\)}}) \(\frac{1}{n-1}\) is still present, but will be partitioned along with variance in order to interpret the results. 
    \end{itemize}
    \item In order to interpret the dispersion, the total variation \(SS_T\) is computed from the combination of \yyy{within-group} variance \yyy{\(SS_E\)} and \xxx{between-group} variance \xxx{\(SS_B\)}, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    SS_{T} = \yyy{SS_{E}} + \xxx{SS_{B}} \quad ~\xxx{\epsilon}=\text{\hyperref[Section: ANOVA Fundamentals]{\ulink{levels}}}, \yyy{n}=\text{subjects in levels},~N=\text{total subjects}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{align*}
      SS_T &= \sum_{\xxx{i} = 1}^{\xxx{\epsilon}}\sum_{\yyy{i} = 1}^{\text{\yyy{n}}}(x_{\xxx{i}\yyy{j}}-\bar{x})^2  &&
      \nu_T = N - 1\\
      \xxx{SS_B} &= \sum_{\xxx{i} = 1}^{\xxx{\epsilon}}(\xxx{\bar{x}_i} - \bar{x})^2 \yyy{n}_\xxx{i} &&
      \xxx{\nu_B} = \xxx{\epsilon} - 1 \\
      \yyy{SS_E} &= \sum_{\xxx{i} = 1}^{\xxx{\epsilon}}\sum_{\yyy{i} = 1}^{\text{\yyy{n}}}(x_{\xxx{i}\yyy{j}}-\xxx{\bar{x}_i})^2  &&
      \yyy{\nu_E} = N-\xxx{\epsilon}
    \end{align*}
  \end{itemize}

  \subsection{F-Test}
  \begin{itemize}
    \item \ddd{\(F\)-test}: used for comparing the factors of the total deviation, represents the mean squared \(MS\) ratio of the \xxx{between-group} variance and \yyy{within-group} variance, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    F = \frac{\text{\xxx{``Explained''} variance}}{\text{\yyy{``Unexplained'} variance}} = \frac{\text{Due to \xxx{factors}}}{\text{\yyy{Natural} variance}} = \frac{\xxx{SS_B/\nu_B}} {\yyy{SS_E / \nu_E}}= \frac{\xxx{MS_B}}{\yyy{MS_E}}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
  \end{itemize}

  \subsection{The ANOVA Table}
  \begin{itemize}
    \item Results from ANOVA are often displayed together in a table, i.e.,
    \medskip
    \begin{center}
      \hspace{-24pt}\begin{tabular}{rccccc}
        \toprule
        Variance & \(SS\) & \(\nu\) & \(MS\) & \(F\) & \(p\)-value \\
        \midrule
        \xxx{Between}  & \xxx{\(SS_B\)} & \(\xxx{\epsilon}-1\) & \xxx{\(MS_B\)} & \(\frac{\xxx{MS_B}}{\yyy{MS_E}}\) & \(p\) \\
        \yyy{Within}   & \yyy{\(SS_E\)} & \(N-\xxx{\epsilon}\) & \yyy{\(MS_E\)} & &  \\
        Total    & \(SS_T\) & \(N-1\) & & &  \\
        \bottomrule
      \end{tabular}
    \end{center}
    \medskip
    \item Again, the \(\fff{H_a}\) is valid when the \hyperref[Subsection: P-Value]{\ulink{p-value is significant}}, meaning at least one group mean is \fff{distinguishable} from at least one other group.
      \begin{itemize}
        \item I.e., the \(\ttt{H_\nil}\) is \rrr{correctly rejected} if \(p \leq \alpha\).
        \item If the \fff{\(H_a\)} is valid, then the \(F\) statistic represents the total variability to be investigated between groups, but does not tell us which groups vary; post-hoc comparisons are required to find the source of such variability.
        \item The \(F\)-test is known to be nearly optimal in the sense for minimizing \hyperref[Subsection: Statistical Errors]{\ulink{false~negatives}} for a fixed rate of \hyperref[Subsection: Statistical Errors]{\ulink{false positives}}.
      \end{itemize}
  \end{itemize}

  \subsection{Post Hoc Comparisons}
  \begin{itemize}
    \item \ddd{Post hoc}: analysis of results after an experiment.
      \begin{itemize}
        \item Often based on \hyperref[Subsection: Multiple Comparisons Problem]{\ulink{family-wise error rate}} analysis, \hyperref[Section: Data Visualization]{\ulink{data visualization}}, and \hyperref[Section: T-Tests]{\ulink{\(t\)-tests}}.
      \end{itemize}
    \item \ddd{Tukey's (range) test}: a single-step multiple comparison procedure to used to find means that are significantly different from each other over a specified range.
      \begin{itemize}
        \item Tukey's test is common post hoc approach for controlling the family-wise error rate, essentially, it is just a \(t\)-test that incorporates such control, i.e.,
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        q_{c,n-c} = \frac{\rrr{\bar{x}_{\max}} - \bbb{\bar{x}_{\min}}}{\sqrt{\xxx{MS_E}}\sqrt{2/n}}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{itemize}
          \item \(c\): the number of comparisons being made.
          \item \(n\): total number of data values.
          \item \(c,n-c = \nu\): the degrees of freedom, which depends on specified number of comparisons being made (the range) that are relevant. 
        \end{itemize}
      \item Similar the \(t\)-test, if \(q\) is larger than the critical value determined by the significance level \(\alpha\), then the means of the comparison are significantly different.
      \end{itemize}
  \end{itemize}
  
  \subsection{Two-Way ANOVA}
  \begin{itemize}
    \item All the methods of ANOVA discussed so far were only being applied to the \hyperref[Subsection: Study Designs]{\ulink{one-way~ANOVA}}\@, but such methods can be extended if multiple factors are present.
    \item Total variation in the dataset is the \emph{sum of the variation across}: \yyy{subjects \(n\)} within each group  + \xxx{levels \(\epsilon\)} within each factor + interactions between the \bBb{factors \(\lambda_x\)}.
    \item \hyperref[Subsection: Sum of Squares]{\ulink{The methods}} can be extended to any factorial ANOVA, but here extension to the two-way ANOVA will be demonstrated:
    \begin{align*}
      SS_T &= 
      \rrr{\sum_{i = 1}^{\xxx{\epsilon_{\bBb{\lambda_1}}}}}
      \emph{\sum_{j = 1}^{\xxx{\epsilon_{\bBb{\lambda_2}}}}}
      \yyy{\sum_{k = 1}^{\yyy{n}}}
      (x_{\rrr{i}\emph{j}\yyy{k}}-\bar{x})^2 
      && \nu_T = N - 1 
      \\
      \xxx{SS_{B\bBb{\lambda_1}}} &= 
      \xxx{\varepsilon}_\bBb{2}\yyy{n}\rrr{\sum_{i = 1}^{\xxx{\epsilon_{\bBb{\lambda_1}}}}}(\rrr{\bar{x}_i}-\bar{x})^2
      && \xxx{\nu_{B\bBb{\lambda_1}}} = \xxx{\varepsilon}_\bBb{1} - 1
      \\
      \xxx{SS_{B\bBb{\lambda_2}}} &= 
      \xxx{\varepsilon}_\bBb{1}\yyy{n}\emph{\sum_{j = 1}^{\xxx{\epsilon_{\bBb{\lambda_2}}}}}(\emph{\bar{x}_j}-\bar{x})^2
      && \xxx{\nu_{B\bBb{\lambda_2}}} = \xxx{\varepsilon}_\bBb{2} - 1
      \\
      SS_{\bBb{\lambda_1} \times \bBb{\lambda_2}} &= 
      \rrr{\sum_{i = 1}^{\xxx{\epsilon_{\bBb{\lambda_1}}}}}
      \emph{\sum_{j = 1}^{\xxx{\epsilon_{\bBb{\lambda_2}}}}}
      (x_{\rrr{i}\emph{j}}-\rrr{\bar{x}_i}-\emph{\bar{x}_j}-\bar{x})^2 
      &&
      \nu_{\bBb{\lambda_1} \times \bBb{\lambda_2}} = \xxx{\nu_{B\bBb{\lambda_1}}}\xxx{\nu_{B\bBb{\lambda_2}}}
      \\
      \yyy{SS_E} &= 
      \rrr{\sum_{i = 1}^{\xxx{\epsilon_{\bBb{\lambda_1}}}}}
      \emph{\sum_{j = 1}^{\xxx{\epsilon_{\bBb{\lambda_2}}}}}
      \yyy{\sum_{k = 1}^{\yyy{n}}}
      (x_{\rrr{i}\emph{j}\yyy{k}}-\bar{x}_{\rrr{i}\emph{j}})^2 
      && \yyy{\nu_E} = N - \xxx{\varepsilon}_\bBb{1}\xxx{\varepsilon}_\bBb{2}
    \end{align*}
    \(\text{Where}~\xxx{\varepsilon}_\bBb{x} = \text{the number of levels within each factor, i.e.,}~\xxx{\epsilon}_n \in \bBb{\lambda_x}\)
  \item Which can also be represented in a table:
  \medskip
    \begin{center}
      \hspace{-24pt}\begin{tabular}{rccccc}
        \toprule
        Variance & \(SS\) & \(\nu\) & \(MS\) & \(F\) & \(p\)-value \\
        \midrule
        \(\bBb{\lambda_1}\) &
        \(\xxx{SS_{B\bBb{\lambda_1}}}\) &
        \(\xxx{\varepsilon}_\bBb{1} - 1\) &
        \(\xxx{MS_{\bBb{\lambda_1}}}\) &
        \(\xxx{MS_{\bBb{\lambda_1}}}/\yyy{MS_E}\)& 
        \(p\) \\
        \(\bBb{\lambda_2}\) &
        \(\xxx{SS_{B\bBb{\lambda_2}}}\) &
        \(\xxx{\varepsilon}_\bBb{2} - 1\) &
        \(\xxx{MS_{\bBb{\lambda_2}}}\) &
        \(\xxx{MS_{\bBb{\lambda_2}}}/\yyy{MS_E}\) &
        \(p\) \\
        \(\bBb{\lambda_1} \times \bBb{\lambda_2}\) &
        \(SS_{\bBb{\lambda_1} \times \bBb{\lambda_2}}\) & 
        \(\xxx{\nu_{B\bBb{\lambda_1}}}\xxx{\nu_{B\bBb{\lambda_2}}}\) &
        \(\xxx{MS}_{\bBb{\lambda_1} \times \bBb{\lambda_2}}\) &
        \(\xxx{MS}_{\bBb{\lambda_1} \times \bBb{\lambda_2}}/\yyy{MS_E}\) &
        \(p\) \\
        \yyy{Within}   
        & \yyy{\(SS_E\)} & \( N - \xxx{\varepsilon}_\bBb{1}\xxx{\varepsilon}_\bBb{2}\) & \yyy{\(MS_E\)} & &  \\
        Total    
        & \(SS_T\) & \(N-1\) & & &  \\
        \bottomrule
      \end{tabular}
    \end{center}
    \medskip
    \item This can be extended, with increasing time complexity.
    \item Using values from a factorial ANOVA in data visualization is often used to interpret results, as mapping interactions can quickly get out of hand.
  \end{itemize}
\end{itemize}
