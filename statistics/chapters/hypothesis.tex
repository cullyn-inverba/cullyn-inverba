\chapter{Hypothesis Testing}

\section{Hypothesis Testing Fundamentals}
\begin{itemize}
  \item Reviewing dependent and independent variables (parameters):
    \begin{itemize}
      \item \ddd{Dependent variable \(y\)}: the variable you are trying to explain; the \yyy{output} of a function.
      \item \ddd{Independent variables \(x_n\)}: the variables that potentially explain the dependent variable; the \xxx{input(s)} to a function.
      \item Often the assumptions about the relationship can effect what is assumed to be the independent and dependent variables; interpretations can be difficult.
    \end{itemize}
  \item \ddd{Models}: a simplified system made of the composition of concepts which are used to help know, understand, or simulate a subject the model represents.
    \begin{itemize}
      \item \ddd{Residual (error) \(\epsilon\)}: the degree that features not explained by variables that make up the composition of models. 
      \item Residuals should be small (\emph{accurate}), but models should also be simple (\emph{useful}); finding the balance between these two goals is a major part of statistics/science.
    \end{itemize}
  \item \ddd{(Alternative; effect) hypothesis \(H_a\)}: a proposed explanation for a phenomenon;a falsifiable claim that requires verification, typically from experimental data, and that allows for predictions about future observations.
    \begin{itemize}
      \item Most formal hypotheses connect concepts by specifying the expected relationships between propositions, leading to expected differences.
      \item Hypothesis testing is used to develop better theories via the rejection of previous theories; most progress in science is the result of hypothesis testing.
      \item A \emph{strong hypothesis} is:
      \begin{multicols}{2}
        \begin{itemize}
          \item \emph{Falsifiable}---ideally testable, makes a criticizable prediction. 
          \item \emph{Parsimonious}---limits excessive entities; application of ``Occam's razor.''
          \item \emph{Scoped}---clear, specific, applicable; a statement, not a question.
          \item \emph{Fruitful}---may explain further phenomena, aids in understanding.
        \end{itemize}
      \end{multicols}
    \end{itemize}

  \item \ddd{Null hypothesis \(H_\nil\)}: the default hypothesis that a quantity to be measure is zero. 
    \begin{itemize}
      \item Typically, a quantity being measure is the difference between two situations, thus support for the alternative hypothesis is gained via \emph{rejection of the null hypothesis}.
      \item Testing the null hypothesis is a central task in hypothesis testing and the modern practice of science; weak evidence fails to reject the null hypothesis.
      \item Criteria for excluding the null hypothesis will be covered in more depth when discussing \hyperref[Chapter: Confidence Intervals]{\dlink{confidence intervals}}.
    \end{itemize}
  
  \subsection{Basis of Inferential Statistics}
  \begin{itemize}
    \item Essentially, the basis of inferential statistics relies on the \emph{comparison} between \hyperref[Section: Sampling]{\ulink{sample distributions}} under the null and alternative hypotheses.
    \item In most cases, \hyperref[Subsection: Population vs. Sample Data]{\ulink{population data}} is not attainable, instead, use of the \hyperref[Subsection: Law of Large Numbers and Central Limit Theorem]{\ulink{central limit theorem}} allows for the \hyperref[Section: Sampling]{\ulink{expected value}} to be found via use of repeated sampling.
      \begin{itemize}
        \item \ddd{\(H_\nil\) distribution}: the distribution created due to \hyperref[Section: Sampling]{\ulink{sampling variability}} under the null hypothesis, i.e., the differences between the expected mean value and sampled mean value, centered around \nil.
          \begin{itemize}
            \item Results from a formula based on assumptions, \hyperref[Subsection: Degrees of Freedom]{\dlink{degrees of freedom}}, and type/nature of particular tests being performed.
          \end{itemize}
        \item \ddd{\(H_a\) distribution}: the distribution of differences due to the alternative hypothesis, rejection of the null hypothesis is likely to occur if observations reflect this distribution and not the \(H_\nil\) distribution.
          \begin{itemize}
            \item Results from empirical observations, gathered data and \hyperref[Subsection: Sampling Methods]{\ulink{sampling methods}}.
          \end{itemize}
      \end{itemize}
    \item Quantifying the differences between the \(H_\nil\) and \(H_a\) requires normalization, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \frac{\text{\ttt{Difference of centers}}}
    {\text{\fff{Widths of distributions}}} = 
    \frac{\text{\ttt{Central Tendency}}}
    {\text{\fff{Dispersion}}} = 
    \frac{\text{\ttt{Signal}}}
    {\text{\fff{Noise}}}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item The investigation of the ratio between \ttt{signal}-to-\fff{noise} is essentially all of inferential statistics; fitting data into workable frameworks contains the majority of the work.
  \end{itemize}
    
  \subsection{P-Value}
  \begin{itemize}
    \item \ddd{\textit{p}-value}: the \hyperref[Section: Probability Fundamentals]{\ulink{probability}} of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypotheses is correct, i.e.,
      \begin{itemize}
        \item How likely is the \(H_a\) value to occur if \(H_\nil\) is correct?
        \item What is the probability of observing a parameter estimate of \(H_a\) or larger, given there is no true effect?
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \emph{\cp{a}}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \item \ttt{Small \(p\)-value} \to~outcome is \ttt{very unlikely} to occur under the \ttt{null hypothesis}.
      \end{itemize}
    \item \ddd{Significance level \(\alpha\)}: the somewhat arbitrary threshold whereby a study would reject the null hypothesis, typically \(\alpha \leq 0.05, 0.01,~\text{or}~0.001\)
    \item \ddd{Statistically significant}: when \(p \leq \alpha\); significance can have \hyperref[Subsection: Interpretations of Significance]{\dlink{other interpretations}}.
    \item Either side of a distribution is unlikely; \emph{two-tailed} distributions need to \emph{split \(\alpha\)}.
      \begin{itemize}
        \item Hypotheses should aim to be one-tailed, but this is often not feasible.
      \end{itemize}
    \item \(p\)-values are often misinterpreted, sometimes even intentionally abused, and an important topic in metascience.
    \item Common misinterpretations of \(p\)-values:
      \begin{itemize}
        \item \false{Incorrect}: 
          \begin{itemize}
            \item ``\textit{My \(p\)-value is 0.02, so the effect is present for 2\% of the population.}''
            \item ``\textit{My \(p\)-value is 0.02, so there is a 90\% chance that my sample statistic equals the population parameter.}''
            \item ``\textit{My p-value is smaller than the threshold, therefore the effect is real.}''
          \end{itemize}
        \item \true{Correct}: 
        \begin{itemize}
          \item ``My \(p\)-value is 0.02, therefore there is a 2\% chance that there is no effect and my sample statistic was due to sampling variability, noise, small sample size, and/or systematic bias.''
        \end{itemize}
      \end{itemize}
    \item Recall that the \hyperref[Subsection: Z-Score Standardization]{\ulink{z-score}} is a dimensionless measure of \hyperref[Subsection: Measures of Dispersion]{\ulink{standard deviations \(\sigma_x\)}} from the mean; the relation between \(p\)- and z-values can be useful to memorize.
    \item Given a Gaussian distribution, z-proportion (above/below) values are:
      \begin{itemize}
        \item 68.3\% of the data are within \(\sigma_1\leftrightarrow z = \pm 1=0.683\) 
        \item 95.5\% of the data are within \(\sigma_2\leftrightarrow z = \pm 2 = 0.955\)
        \item 99.7\% of the data are within \(\sigma_3\leftrightarrow z = \pm 3 = 0.997\)
      \end{itemize}
    \item Common \(p\)-values parings with standard deviations:
    \vspace{-6pt}
    \begin{multicols}{2}
      \begin{itemize}
        \item One-tailed \(\downarrow\)
        \item \(p=0.05 \leftrightarrow z = 1.64\)
        \item \(p=0.01 \leftrightarrow z = 2.32\)
        \item \(p=0.001 \leftrightarrow z = 3.09\)
        \item \(\downarrow\) Two-tailed \(\downarrow\)
        \item \(p=0.05 \leftrightarrow z = 1.96\)
        \item \(p=0.01 \leftrightarrow z = 2.58\)
        \item \(p=0.001 \leftrightarrow z = 3.29\)
      \end{itemize}
    \end{multicols}
  \end{itemize}
  
  \subsection{Degrees of Freedom}
  \begin{itemize}
    \item \ddd{Degrees of freedom (d.f. \(\nu\))}: the number of values in the final calculation of a statistic that are free to vary.
      \begin{itemize}
        \item I.e., the minimum number of independent coordinates that can specify the position of the system completely.
      \end{itemize}
    \item Degrees of freedom determine the shape of \(H_\nil\) distributions (often the width).
    \item Higher degrees of freedom generally indicate more \hyperref[Chapter: Statistical Power and Sample Sizes]{\dlink{power to reject}} the \(H_\nil\).
    \item Can be useful metric for quickly determining relevant accuracy and understanding of experimental designs.
    \item Generally, \emph{\(\nu = n - k\)}; with \(n\) data points and \(k\) parameters.
  \end{itemize}

  \subsection{Statistical Errors}
  \begin{itemize}
    \item \ddd{\fff{False positive (type I error) \(p = \alpha\)}}: an \textbf{\fff{incorrect rejection}} of a \ttt{true \(H_\nil\)}.
      \begin{itemize}
        \item \ddd{\rrr{True positive \(p = 1-\beta\)}}: a \rrr{\textbf{correct rejection}} of a \fff{false \(H_\nil\)}.
      \end{itemize}
    \item \ddd{\XXX{False negative (type II error) \(p= \beta\)}}: an \textbf{\XXX{incorrect non-rejection}} of a \fff{false \(H_\nil\)}.
      \begin{itemize}
        \item \ddd{\bbb{True negative \(p = 1-\alpha\)}}: a \bbb{\textbf{correct non-rejection}} of a \ttt{true \(H_\nil\)}.
      \end{itemize}
    \item \ddd{``Overlap''}: the area shared between the \(H_\nil\) and the \(H_a\).
      \begin{itemize}
        \item Adjustments to the significance level \(\alpha \) can bias towards/away from either false negatives/positives, at the cost of increasing the other.
        \item Sometimes one error is more costly than the other, however, changing \(\alpha\) is a less than ideal way generally arbitrary way to minimize error.
      \end{itemize}
      \item The best way to minimize error is to minimize \ttt{signal}-to-\fff{noise}, i.e.,
      \begin{itemize}
        \item \ttt{Increase distance between} distributions (\ttt{bigger effects})
        \item \fff{Decrease the width} of the distributions (\fff{less variability}).
      \end{itemize}
    \begin{center}
      \Image{0.8\columnwidth}{chapters/images/errors.png}
    \end{center}
  \end{itemize}
  \subsection{Interpretations of Significance}
  \begin{itemize}
    \item \ddd{Statistical significance}: the probability of observing a test statistic of a certain magnitude given the \(H_\nil\) is true.
    \item \ddd{Theoretical significance}: a finding that is relevant for a theory or leads to a new experiment; not directly related to statistical significance. 
    \item \ddd{Clinical (practical, societal, educational)}: a finding is relevant for application in a particular field of interest. 
  \end{itemize}
\end{itemize}

\section{Testing Properties}
\begin{itemize}
  \item []

  \subsection{Parametric vs. Nonparametric}
  \begin{itemize}
    \item \ddd{Parametric statistics}: based on the assumptions wherein the sample data originates from a population that can be adequately modeled by a probability distribution with \OOO{a fixed set of parameters}.
    \item \ddd{Nonparametric statistics}: based on \bBb{relaxed assumptions} surrounding of parametric tests, e.g., underlying distribution less important, presence of outliers, or lower specificity of parameters.
    \item Generally, there is a nonparametric test related to each parametric test, with particular assumptions relaxed, e.g., 
    \bigskip
    \begin{table}[h]
      \centering
      \begin{tabular}{rl}
        \ddd{Parametric} &  
        \ddd{Nonparametric}  \\
        \hyperref[Subsection: One-Sample T-Test]{\dlink{1-sample \(t\)-test}} &
         \hyperref[Subsection: Nonparametric T-Tests]{\dlink{Wilcoxon sign-rank test}} \\
        \hyperref[Subsection: Two-Sample T-Test]{\dlink{2-sample \(t\)-test}} &
         \hyperref[Subsection: Nonparametric T-Tests]{\dlink{Mann-Whitney U test}} \\
        \hyperref[Chapter: Correlation]{\dlink{Pearson correlation}} &
         \hyperref[Chapter: Correlation]{\dlink{Spearman correlation}} \\
        \hyperref[Chapter: Analysis of Variance]{\dlink{ANOVA}} &
         \hyperref[Chapter: Analysis of Variance]{\dlink{Kruskal-Wallis test}}\\
        \end{tabular}
    \end{table}
    \item Important applications of nonparametric statistics with no direct correlate involve \hyperref[Subsection: Primer: Permutation Testing]{\dlink{permutation testing}} and \hyperref[Subsection: Primer: Cross-Validation]{\dlink{cross-validation}}.
    \item \true{\!Advantages} and \false{\!limitations (sometimes)} of \ddd{parametric statistics}:
    \begin{multicols}{2}
      \begin{itemize}
        \item \true{\! Standard, widely used}
        \item \true{\! Computationally efficient/simple}
        \item \true{\! Analytically proven}
        \item \false{\! Based on assumptions}
        \item \false{\! Assumptions can be hard to test}
        \item \false{\! Violations can be inscrutable}
      \end{itemize}
    \end{multicols}
    \item \true{\!Advantages} and \false{\!limitations (sometimes)} of \ddd{nonparametric statistics}:
    \begin{multicols}{2}
      \begin{itemize}
        \item \true{\! ``No'' assumptions necessary}
        \item \true{\! Appropriate for non-numeric data}
        \item \true{\! Appropriate for small sample sizes}
        \item \false{\! Can be ``block box'' algorithms}
        \item \false{\! Can be inefficient/slow}
        \item \false{\! Results can vary each run}
      \end{itemize}
    \end{multicols}
    \item In general, use:
      \begin{itemize}
        \item \OOO{Parametric} methods when \OOO{possible}.
        \item \bBb{Nonparametric} methods when \bBb{necessary}.
      \end{itemize} 
  \end{itemize}

  \subsection{Multiple Comparisons Problem}
  \begin{itemize}
    \item \ddd{Multiplicity (multiple comparison problem)}: the increase of erroneous inferences when comparing a set of statistical inferences simultaneously, or when inferring a subset of parameters based on the observed values.
      \begin{itemize}
        \item As more attributes are compared, the more likely it becomes that observed outcome is due to sampling error, as probabilities are additive.
        \item E.g., despite all the alternative hypotheses have a statistical significant value individually (5\%), together they provide a high rate of \hyperref[Subsection: Statistical Errors]{\ulink{type I errors \(\alpha \)}}, i.e.,
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \cp{1} + \cp{2} + \cp{3} = \fff{0.15} = \fff{\alpha}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \item The above is just a comparing against the \(H_\nil\), the problem becomes much worse when including pairwise comparisons between all \(H_a\) in the set (\fff{15\%\,\to\,30\% \(\alpha \)}).
      \end{itemize}
    \item Common conceptualizations of multiplicity problem can be done via descriptions of errors rates, e.g.,
      \begin{itemize}
        \item \ddd{Family-wise error rate (FWER) \(\tilde{\alpha}\)}: the probability of making \emph{at least one} \fff{false positive} when performing multiple hypotheses tests, i.e.,
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \tilde{\alpha} = 1 - (1-\fff{\alpha}_i)^m \leftrightarrow p(\fff{\alpha} \geq 1)
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{itemize}
          \item \(i =\text{per comparison}\), \(m=\text{total hypotheses tested}\)
        \end{itemize}
        \item \ddd{False discovery rate (FDR) \(E[Q]\)}: the \emph{expected} proportion \(Q\) of \fff{false positives} relative to total number of \rrr{true positives \(1-\beta\)}, i.e.,
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        E[Q] = \frac{\fff{\alpha}}{(\fff{\alpha}+\rrr{(1-\XXX{\beta})})}\qquad \XXX{\beta=\text{false negative}}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \end{itemize}
    \item Each conceptualization can have a variety of relevant controlling procedures that are used to correct for multiplicity issues, e.g,
      \begin{itemize}
        \item \ddd{Bonferroni correction}: a conservative method, free of dependence and distributional assumptions, wherein the \fff{false positive rate per comparison} is simply divided by the total number of hypotheses \(m\) tested, i.e.,
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \fff{\alpha}_i = \frac{\fff{\alpha}}{m} \leftrightarrow \text{reject \(H_i\) if} \leq \frac{\fff{\alpha}}{m} 
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \item \ddd{Šidák correction}: slightly more powerful than Bonferroni, but with small gain and potential to fail when tests are negatively dependent; found via solving the FWER equation, i.e.,
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \fff{\alpha}_i = 1 - (1-\alpha)^{1/m}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \item Controlling procedures for false discovery rate not described, I'm not sure relevance as of now---might revisit later.
      \end{itemize}
  \end{itemize}

  \subsection{Primer: Cross-Validation}
    \begin{itemize}
    \item \ddd{Cross-validation}: a set of model validation techniques for assessing how well statistical analysis will generalize via parcelization of given data. 
      \begin{itemize}
        \item Mainly used to estimate how accurate a predictive model might be in practice for \hyperref[Subsection: Data Types]{\ulink{nominal and ordinal data}} (discrete is also possible).
        \item \ddd{Training set (known data)}: the portion of given data that a predictive model is used to train on. 
        \item \ddd{Testing set (unknown data)}: the portion of data set aside to later estimate accuracy of the trained model.
      \end{itemize}
    \item Cross-validation is used on models with one or more unknown parameters, wherein a dataset is used to fit the data to the parameter via optimization.
      \begin{itemize}
        \item \ddd{Optimization}: selection of the best element, with regard to some criterion, from some set of available alternatives.
        \item \ddd{Overfitting}: when analysis \emph{corresponds too closely} to a particular dataset, leading to poor predictive performance
        \item \ddd{Underfitting}: when analysis \emph{fails to capture} the underlying structure of the data, leading to poor predictive performance.
      \end{itemize}
    \item Cross-validation is of greater importance when dealing with \hyperref[Chapter: Regression]{\dlink{regression}} and \hyperref[Chapter: Confidence Intervals]{\dlink{confidence intervals}}.
      \begin{itemize}
        \item In-depth discussion will occur later, including distinctions between \hyperref[Subsection: Exhaustive vs. Non-Exhaustive]{\dlink{exhausting~and~non-exhaustive}} methods. 
        \item In most methods, multiple rounds of cross-validation are performed using different partitions, with the results being combined over the rounds.
      \end{itemize}
  \end{itemize}

  \subsection{P-Value vs. Classification Accuracy}
  \bigskip
  \begin{table}[h]
    \centering
    \begin{tabular}{rl}
      \ddd{P-Value} & \ddd{Accuracy}  \\
      Tests of probability of sample & Model outcome vs.\ observed outcome  \\
      Parameter based scoring  & Individual parameters uncertain \\
      Analytical solutions, theoretical & Empirically informed, inconsistent \\
      Works for most model/variable types & Restricted by model/variable type   \\
      Sensitive to extreme sample sizes & Robust to sample sizes \\
      \end{tabular}
  \end{table}
  
\end{itemize}

\section{T-Tests}
\begin{itemize}
  \item []
  
  \subsection{Assumptions and Uses of T-Tests}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{One-Sample T-Test}
  \begin{itemize}
    \item 
  \end{itemize}
  
  \subsection{Two-Sample T-Test}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{Nonparametric T-Tests}
  \begin{itemize}
    \item 
  \end{itemize}
  
  \subsection{Primer: Permutation Testing}
  \begin{itemize}
    \item 
  \end{itemize}
  
  
\end{itemize}
