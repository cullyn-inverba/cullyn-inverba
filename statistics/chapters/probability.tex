\chapter{Probability Theory}

\section{Probability Fundamentals}
\begin{itemize}
  \item \ddd{Probability}: a measure of the likelihood that an event will occur; used to quantify attitudes towards propositions whose truth are not certain.
    \begin{itemize}
      \item Quantitatively, probability is a number between 0 and 1, which is often expressed as a percentage.
    \end{itemize}
  \item \ddd{Probability theory}: the axiomatic formalization of probability; widely used in many fields of study from math to philosophy.
  \item \ddd{Probability space \((\Omega, \F, P)\)}: a formal construct consisting of three elements that provides a model for a random process.
    \begin{itemize}
      \item \ddd{Sample space \(\Omega\)}: the set of all possible outcomes.
      \item \ddd{Event space \(\F\)}: all sets of outcomes; all subsets of the sample space.
      \item \ddd{Probability function \(P(E)\)}: the assignment of a number between 0 and 1 that represents the probability of each event \(E\) in event space.
    \end{itemize}
  \item \ddd{Proportion}: the measure of certainty; a fraction of a whole or the relation between two varying quantities.
    \begin{itemize}
      \item Proportion \textit{could} involve random variables, so depending on how the question is asked, then proportion could be the same as probability, but ultimately they are not interchangeable.
    \end{itemize}
  \item \ddd{Odds}: the ratio of the number of events that produce an outcome to the number of events that do not; essentially probability reframed in potentially more efficient way.

  \subsection{Probability Theory Axioms}
  \begin{itemize}
    \item \ddd{First axiom}: the probability of an event is a \emph{non-negative number real number}, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    P(E) \in \R,\quad P(E)\geq 0 \qqquad \forall E \in \F
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item \ddd{Second axiom}: the assumption of unit measure; the probability that \emph{at least one elementary event} in the entire sample space \emph{will occur} is 1, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    P(\Omega) = 1
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item \ddd{Third axiom}: the assumption of \(\sigma \)-additivity, wherein any \emph{countable} sequence of \hyperref[Subsection: Independent and Mutually Exclusive Events]{\dlink{disjoint sets}} \(E_1,E_2,\ldots\) satisfies
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    P\left(\bigcup_{i=1}^{\infty}E_i\right) = \sum_{i = 1}^{\infty}P(E_i)
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
      \item Thus, only \hyperref[Subsection: Data Types]{\ulink{discrete data}} are valid for probability; continuous data must be converted to discrete forms in order to be valid.
    \end{itemize}
  \end{itemize}

  \subsection{Independent and Mutually Exclusive Events}
  \begin{itemize}
    \item \ddd{Stochastically independent}: when an event does not affect the probability of another, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    P(A~\ttt{\text{and}}~B)=P(A\cap B)=P(A)P(B)
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
      \item Two random variables are independent if the realization of one does not affect the probability distribution of the other.
      \item \ddd{Pairwise independent (weak notion)}: two specific events in a collection that are independent of each other.
      \item \ddd{Mutually independent (strong notion)}: when each event is independent of any combination of other events in the collection.
      \item Often the stronger notion is simply termed independence, as it implies the weaker version, but not the other way around.
    \end{itemize}
    \item \ddd{Mutually exclusive (disjoint)}: two events that cannot occur at the same time, i.e., 
    \begin{itemize}
      \item Probability of \ttt{both}:
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      P(A~\text{\ttt{and}}~B) = P(A\cap B)= \minor{0} 
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \item Probability of \fff{either}: \(\hspace{182pt}\minor{\downarrow}\)
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      P(A~\fff{\text{or}}~B)=P(A\cup B)=  P(A)+P(B) - \minor{P(A\cap B)} = P(A)+P(B) 
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \end{itemize}
    \item \ddd{Collectively exhaustive (jointly)}: when at least one event must occur while exhausting all other possibilities at a given time, or that their union must coverall the events within the entire sample space, i.e., 
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    A\cup B = \Omega
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
  \end{itemize}
  
  \subsection{Primer: Conditional Probability}
  \begin{itemize}
    \item \ddd{Conditional probability}: the probability of some event \(A\), given \(|\) the occurrence of some other event \(B\), i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    P(A~|\iipt B)=\frac{P(A\cap B)}{P(B)}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
      \item Note, \(P(A\iipt | \ipt B)\) typically differs from \(P(B \iipt | \ipt A)\), falsely equating the two often results in errors, termed the base rate fallacy.
    \end{itemize}
    \item \ddd{Bayes' theorem}: probability of an event based on prior knowledge of conditions that might be related to the event; inference using conditional probability, i.e.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    P(A~|\iipt B)=\frac{P(B\,|\iipt A)P(A)}{P(B)}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item More on Bayesian statistics may or not be explored in greater depth in this course.
  \end{itemize}
  
\end{itemize}

\section{Probability Functions}
\begin{itemize}
  \item []
  
  \subsection{Probability Mass vs. Density}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{Cumulative Density Function}
  \begin{itemize}
    \item 
  \end{itemize}
  
\end{itemize}

\section{Sample Distributions}
\begin{itemize}
  \item[]
  
  \subsection{Random, Representative Sampling}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{Monte Carlo Methods}
  \begin{itemize}
    \item 
  \end{itemize}
  
  \subsection{Sample Variability}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{Expected Value}
  \begin{itemize}
    \item 
  \end{itemize}
  
\end{itemize}

\section{Convergence of Random Variables}
\begin{itemize}
  \item[]
  
  \subsection{Law of Large Numbers}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{Central Limit Theorem}
  \begin{itemize}
    \item 
  \end{itemize}
  
\end{itemize}
