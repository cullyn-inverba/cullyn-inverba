\chapter{Matrix Multiplication}\label{Matrix Multiplication}
\section{Standard Matrix Multiplication}\label{Standard Matrix Multiplication}
\begin{itemize}
  \item \jjj{Standard matrix multiplication \(\bm{AB}\)}: a binary operation that produces a matrix from two matrices whose \emph{inner dimensions match}.
    \begin{itemize}
      \item Multiplication of matrices can be thought of as going from right to left (\(\bm{A}\leftarrow\bm{B}\)), or rather, \rrr{\tbm{B} post-multiplies \tbm{A}}, or \bbb{\tbm{A} pre-multiplies \tbm{B}},
      \item The number of \yyy{columns (\(n\)) in the first matrix} must be \ttt{equal to} the number of \\ \xxx{rows (\(m\)) in the second matrix}.
      \item \jjj{Matrix product}: the product, whose size is equal to \xxx{rows of the first matrix} and the number of \yyy{columns of the second matrix}.
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      (\xxx{m_1} \times \ttt{n_1})(\ttt{m_2} \times \yyy{n_2}) = \xxx{m_1} \times \yyy{n_2}
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \end{itemize}
  \item \hyperref[Transposition]{\ulink{Transposing}} a matrix switches the dimensions, so it can enable computation in some cases, e.g,
  \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \underbrace{\bm{A}}_{\xxx{5}\times \yyy{7}} = \underbrace{\bm{A}^T}_{\xxx{7}\times \yyy{5}} 
  \qquad
  \underbrace{\bm{A}^T}_{\xxx{7}\times \ttt{5}} 
  \underbrace{\bm{B}}_{\ttt{5}\times \yyy{2}} = \underbrace{\bm{C}}_{\xxx{7}\times\yyy{2}} 
  \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Revisiting the \hyperref[The Dot Product]{\ulink{dot (inner) product}} and the \hyperref[Outer Product]{\ulink{outer product}} of vectors:
  \begin{itemize}
    \item The dot product must have equal-length vectors since the transpose of left vector makes inner dimensions much match, e.g.,
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \underbrace{\bm{v}}_{5\times1}\underbrace{\bm{w}}_{5\times1}
    \to
    \underbrace{\bm{v}^T}_{\xxx{1}\times \ttt{5}}\underbrace{\bm{w}}_{\ttt{5}\times\yyy{1}}
    = 1\times 1~\text{(scalar)}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item However, the transpose of the right vector makes the \(1 \times 1\) dimensions match, making the outer dimensions irrelevant to the validity of the computation, e.g., 
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \underbrace{\bm{v}}_{6\times1}\underbrace{\bm{w}}_{9\times1}
    \to
    \underbrace{\bm{v}}_{\xxx{6}\times \ttt{1}}\underbrace{\bm{w}^T}_{\ttt{1}\times\yyy{9}}
    = 6\times 9~\text{(matrix)}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \end{itemize}

  \subsection{Standard Matrix Multiplication Perspectives}\label{Standard Matrix Multiplication Perspectives}
  \begin{itemize}
    \item There are four ways to compute and conceptualize the process of multiplication of two matrices, all of which give the same result.
    \item I.e, if \tbm{A} is an \(\xxx{m} \times \ttt{n}\) matrix and \tbm{B} is an \(\ttt{n} \times \yyy{p}\) matrix, then their product \tbm{C} =
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \hspace{-25pt}
    {\begin{bmatrix}
      a_{11}b_{11} + \cdots + a_{1\ttt{n}}b_{\ttt{n}1}&a_{11}b_{12} + \cdots + a_{1\ttt{n}}b_{\ttt{n}2} &\cdots &a_{11}b_{1\yyy{p}} + \cdots + a_{1\ttt{n}}b_{\ttt{n}\yyy{p}}
      \\ a_{21}b_{11} + \cdots + a_{2\ttt{n}}b_{\ttt{n}1}&a_{21}b_{12} + \cdots + a_{2\ttt{n}}b_{\ttt{n}2}&\cdots &a_{21}b_{1\yyy{p}} + \cdots + a_{2\ttt{n}}b_{\ttt{n}\yyy{p}}
      \\ \vdots &\vdots &\ddots &\vdots 
      \\ a_{\xxx{m}1}b_{11} + \cdots + a_{\xxx{m}\ttt{n}}b_{\ttt{n}1}&a_{\xxx{m}1}b_{12} + \cdots + a_{\xxx{m}\ttt{n}}b_{\ttt{n}2}&\cdots &a_{\xxx{m}1}b_{1\yyy{p}} + \cdots + a_{\xxx{m}\ttt{n}}b_{\ttt{n}\yyy{p}}
    \end{bmatrix}}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item \jjj{The element perspective}: building the product matrix directly, one element at a time, via the computation of the \hyperref[The Dot Product]{\ulink{dot product}} between the \xxx{rows of the left matrix} and the \yyy{columns of the right matrix}.
    \begin{align*}
    \begin{bmatrix} \xxx{1} & \xxx{2} \\ 3 & 4 \end{bmatrix}
    \begin{bmatrix} \yyy{a} & b \\ \yyy{c} & d \end{bmatrix}
    &=
    \begin{bmatrix}
    \xxx{1}\yyy{a} + \xxx{2}\yyy{c} & \cdots \\ \cdots & \cdots \end{bmatrix}
    \\%
    \begin{bmatrix} \xxx{1} & \xxx{2} \\ 3 & 4 \end{bmatrix}
    \begin{bmatrix} a & \yyy{b} \\ c & \yyy{d} \end{bmatrix}
    &=
    \begin{bmatrix}
    1a + 2c & \xxx{1}\yyy{b}+\xxx{2}\yyy{d} \\ \cdots & \cdots 
    \end{bmatrix}
    \\%
    \begin{bmatrix} 1 & 2 \\ \xxx{3} & \xxx{4} \end{bmatrix}
    \begin{bmatrix}  \yyy{a} & b \\ \yyy{c} & d \end{bmatrix}
    &=
    \begin{bmatrix}
    1a + 2c & 1b+2d \\ \xxx{3}\yyy{a}+\xxx{4}\yyy{c} & \cdots 
    \end{bmatrix}
    \\%
    \begin{bmatrix} 1 & 2 \\ \xxx{3} & \xxx{4} \end{bmatrix}
    \begin{bmatrix} a & \yyy{b} \\ c & \yyy{d} \end{bmatrix}
    &=
    \begin{bmatrix}
    1a + 2c & 1b+2d \\ 3a+4c & \xxx{3}\yyy{b}+\xxx{4}\yyy{d} 
    \end{bmatrix}
    \end{align*}
    \item This is generally the most common perspective as the others methods have all have two ``pseudo steps'' to reach the final product, rather than through one direct method.
    \item \jjj{The layer perspective}: the building of the product matrix one layer at a time, followed by a ``flattening'' to make the final product.
      \begin{itemize}
        \item Each layer is the same size \((\xxx{m_1} \times \yyy{n_2})\) as the product, but is only a \hyperref[Matrix Rank]{\dlink{rank~1~matrix}}, or essentially the representation of only one column's worth of information.
        \item Can be thought of as a \yyy{left matrix of columns} and a \xxx{right matrix of rows}, resulting in the computation of the \hyperref[Outer Product]{\ulink{outer product}}.
      \end{itemize}
    \begin{align*}
    \begin{bmatrix} \yyy{1} & 2 \\ \yyy{3} & 4 \end{bmatrix}
    \begin{bmatrix} \xxx{a} & \xxx{b} \\ c & d \end{bmatrix}
    &=
    \begin{bmatrix}
    \yyy{1}\xxx{a} & \yyy{1}\xxx{b} \\
    \yyy{3}\xxx{a} & \yyy{3}\xxx{b} 
    \end{bmatrix}
    \\
    \begin{bmatrix} 1 & \yyy{2} \\ 3 & \yyy{4} \end{bmatrix}
    \begin{bmatrix} a & b \\ \xxx{c} & \xxx{d} \end{bmatrix}
    &=
    \begin{bmatrix}
    \yyy{2}\xxx{c} & \yyy{2}\xxx{d} \\
    \yyy{4}\xxx{c} & \yyy{4}\xxx{d} 
    \end{bmatrix}
    \\
    \begin{bmatrix}
      \yyy{1}\xxx{a} & \yyy{1}\xxx{b} \\
      \yyy{3}\xxx{a} & \yyy{3}\xxx{b} 
    \end{bmatrix}
    \Downarrow
    \begin{bmatrix}
      \yyy{2}\xxx{c} & \yyy{2}\xxx{d} \\
      \yyy{4}\xxx{c} & \yyy{4}\xxx{d} 
    \end{bmatrix}
    &=
    \begin{bmatrix}
      \yyy{1}\xxx{a} + \yyy{2}\xxx{c} & \yyy{1}\xxx{b}+\yyy{2}\xxx{d} \\ \yyy{3}\xxx{a}+\yyy{4}\xxx{c} & \yyy{3}\xxx{b}+\yyy{4}\xxx{d}  
    \end{bmatrix}
    \end{align*}
    \item \jjj{The column perspective}: the building of the product matrix by columns, where the first column is the sum of the two columns of the left matrix weighted (scaled) by the elements of the first column of the right matrix. 
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \begin{bmatrix} \bbb{1} & \chap{2} \\ \bbb{3} & \chap{4} \end{bmatrix}
      \begin{bmatrix} \rrr{a} & \emph{b} \\ \rrr{c} & \emph{d} \end{bmatrix}
      =
      \begin{pmatrix}
      \rrr{a} \begin{bmatrix} \bbb{1} \\ \bbb{3} \end{bmatrix} + \rrr{c} \begin{bmatrix} \chap{2} \\ \chap{4} \end{bmatrix} &
      \emph{b} \begin{bmatrix} \bbb{1} \\ \bbb{3} \end{bmatrix} + \emph{d} \begin{bmatrix} \chap{2} \\ \chap{4} \end{bmatrix}
      \end{pmatrix}
      =
      \begin{bmatrix}
        \bbb{1}\rrr{a} + \chap{2}\rrr{c} & \bbb{1}\emph{b}+\chap{2}\emph{d} \\ \bbb{3}\rrr{a}+  \chap{4}\rrr{c} & \bbb{3}\emph{b}+\chap{4}\emph{d} 
      \end{bmatrix}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item \jjj{The row perspective}: similar to the column perspective, but building up by row. 
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{bmatrix} \bbb{1} & \bbb{2} \\ \chap{3} & \chap{4} \end{bmatrix}
    \begin{bmatrix} \rrr{a} & \rrr{b} \\ \emph{c} & \emph{d} \end{bmatrix}
    =
    \begin{pmatrix}
    \bbb{1} \begin{bmatrix} \rrr{a} & \rrr{b} \end{bmatrix} + 
    \bbb{2} \begin{bmatrix} \emph{c} & \emph{d} \end{bmatrix} \\
    \chap{3} \begin{bmatrix} \rrr{a} & \rrr{b} \end{bmatrix} + 
    \chap{4} \begin{bmatrix} \emph{c} & \emph{d} \end{bmatrix}
    \end{pmatrix}
    =
    \begin{bmatrix}
      \bbb{1}\rrr{a} + \bbb{2}\emph{c} & \bbb{1}\rrr{b}+\bbb{2}\emph{d} \\ \chap{3}\rrr{a}+\chap{4}\emph{c} & \chap{3}\rrr{b}+\chap{4}\emph{d} 
    \end{bmatrix}
  \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \end{itemize}
\end{itemize}

\section{Applications of Matrix Multiplication}\label{Applications of Matrix Multiplication}
\begin{itemize}
  \item[] 
  \subsection{Diagonal Matrix Multiplication}\label{Diagonal Matrix Multiplication}
  \begin{itemize}
    \item Square \hyperref[Diagonal and Triagnular Matrices]{\ulink{diagonal matrices}} are often used to scale another matrix by the elements along such diagonal.
    \item You can scale the columns or rows depending on the placement of the diagonal matrix \(\bm{D}\) relative to original matrix \(\bm{M}\). 
      \begin{itemize}
        \item \rrr{Post-multiplying} by the diagonal results in the scaling by \yyy{columns}, i.e., same as diagonal matrix multiplication above\(\bm{M}\yyy{\bm{D}}\):
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6 \\
        7 & 8 & 9 
        \end{bmatrix}
        \begin{bmatrix}
        \yyy{a} & 0 & 0 \\
        0 & \yyy{b} & 0 \\
        0 & 0 & \yyy{c}
        \end{bmatrix}
        =
        \begin{bmatrix}
          \yyy{a}1 & \yyy{b}2 & \yyy{c}3 \\
          \yyy{a}4 & \yyy{b}5 & \yyy{c}6 \\
          \yyy{a}7 & \yyy{b}8 & \yyy{c}9 
          \end{bmatrix}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \item \bbb{Pre-multiplying} by the diagonal results in the scaling by \xxx{rows}, i.e., \(\xxx{\bm{D}}\bm{M}\):
        \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6 \\
        7 & 8 & 9 
        \end{bmatrix}
        \begin{bmatrix}
        \xxx{a} & 0 & 0 \\
        0 & \xxx{b} & 0 \\
        0 & 0 & \xxx{c}
        \end{bmatrix}
        =
        \begin{bmatrix}
          \xxx{a}1 & \xxx{a}2 & \xxx{a}3 \\
          \xxx{b}4 & \xxx{b}5 & \xxx{b}6 \\
          \xxx{c}7 & \xxx{c}8 & \xxx{c}9 
          \end{bmatrix}
        \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \end{itemize}
    \item Again, when all the elements along the diagonal are the same, then it is simply a scaled version of the \hyperref[Identity and Zero Matrices]{\ulink{identity matrix}}, or sometimes referred to as a \hyperref[scaled matrix]{\ulink{scaling matrix}}.
  \end{itemize}

  \subsection{Order of Operations}\label{Order of Operations}
  \begin{itemize}
    \item \minor{``And love is evol, spell it backwards, I'll show ya''}
    \item \jjj{\(\bm{(L\,O\,VE)}^T = \bm{E}^T\bm{V}^T\bm{O}^T\bm{L}^T\)}: reversing the order of multiplication on a set of matrices is valid if the same operation (e.g., \hyperref[Transposition]{\ulink{transpose}} or \hyperref[Matrix Inverse]{\dlink{inverse}}) can be applied to each matrix, e.g, (\emph{diagonal} highlighted for easier time seeing transpose)
    \begin{align*}
    \begin{pmatrix}
      \begin{bmatrix} \emph{1} & 2 \\ 3 & \emph{4} \end{bmatrix}
      \begin{bmatrix} \emph{a} & b \\ c & \emph{d} \end{bmatrix}
    \end{pmatrix}^T
    &=
    \begin{bmatrix}
      \emph{1a+2c} & 1b+2d \\ 3a+4c & \emph{3b+4d} 
    \end{bmatrix}^T
    &= 
    \begin{bmatrix}
      \emph{1a+2c} & 3a+4c \\ 1b+2d & \emph{3b+4d} 
    \end{bmatrix}
    \\
    \begin{bmatrix} \emph{a} & b \\ c & \emph{d} \end{bmatrix}^T
    \begin{bmatrix} \emph{1} & 2 \\ 3 & \emph{4} \end{bmatrix}^T
    &=
    \begin{bmatrix} \emph{a} & c \\ b & \emph{d} \end{bmatrix}
    \begin{bmatrix} \emph{1} & 3 \\ 2 & \emph{4} \end{bmatrix}
    &=
    \begin{bmatrix}
      \emph{1a+2c} & 1b+2d \\ 3a+4c & \emph{3b+4d} 
    \end{bmatrix}
    \end{align*}
  \end{itemize}
  
  \subsection{Matrix Vector Multiplication}\label{Matrix Vector Multiplication}
  \begin{itemize}
    \item Multiplying a matrix by a vector always results in a vector, regardless order. 
    \item The order of multiplication does impact the orientation and size (dimensionality) of the product vector, i.e.,
    \\ \rrr{post-multiplication} \to~\yyy{column vector} (weighted combinations of the columns of \tbm{A})
    \\ \bbb{pre-multiplication} \to~\xxx{row vector}
    (weighted combinations of the rows of \tbm{A})
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \underbrace{\bm{A}}_{\xxx{m}\times\ttt{n}}\underbrace{\rrr{\bm{w}}}_{\ttt{m}\times\yyy{1}}=\yyy{\underbrace{\bm{v}}_{\xxx{m}\times\yyy{1}}}
    \qquad 
    \underbrace{\bbb{\bm{w}^T}}_{\xxx{1}\times\ttt{n}}\underbrace{\bm{A}}_{\ttt{m}\times\yyy{n}}=\xxx{\underbrace{\bm{v}}_{\xxx{1}\times\yyy{n}}}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item The order of multiplication does not matter when multiplying a vector with a \hyperref[Symmetric and Skew-Symmetric Matrices]{\ulink{symmetric matrix}}:
    \begin{align*}
      \ttt{\bm{S}^T} &= \ttt{\bm{S}} & \text{symmetric matrix}\\
      \bm{S}\bm{w} &= \yyy{\bm{v}} & \text{column vector}\\ 
      (\bm{S}\bm{w})^T &= \xxx{\bm{v}^T} & \text{apply transpose \rightarrow~row vector}\\ % chktex 3
      \bm{w}^T \bm{S}^T &= \bm{v}^T & \text{\hyperref[Order of Operations]{\ulink{love \leftrightarrow~evol}}}\\
      \bm{w}^T \ttt{\bm{S}} &= \bm{v}^T & \text{symmetric matrix \leftrightarrow~transpose}\\
      \xxx{\bm{v}^T} &= \yyy{\bm{v}} & \text{row vector \leftrightarrow~column vector}
    \end{align*}
    \item If \(\bm{S^T}\neq\bm{S}\), then order does matter, resulting in different product vectors.
    \item Multiplication of vectors and matrices form the basis of \hyperref[tbd]{\dlink{linear transformations}}.
    \item When multiplication between a matrix and vector is equal to the multiplication between a scalar and the same vector, then the scalar is the \hyperref[tbd]{\dlink{eigenvalue}} and the vector is the \hyperref[tbd]{\dlink{eigenvector}}. 
  \end{itemize}
  
  \subsection{Additive and Multiplicative Matrices}\label{Additive and Multiplicative Matrices}
  \begin{itemize}
    \item \jjj{Multiplicative identity matrix}: commonly referred to as the \hyperref[Identity and Zero Matrices]{\ulink{identity matrix}}, where both \bbb{pre} and \rrr{post} multiplication are equal and both produce the original matrix.
    \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \bbb{\bm{I}} \bm{M} = \bm{M}\rrr{\bm{I}} = \bm{M}
    \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
      \item However, addition of the multiplicative identity matrix does not yield the same product, i.e.,
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \bm{M} + \bm{I} \neq \bm{M}
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \end{itemize}
  \item \jjj{Additive identity matrix}: the compliment to the multiplicative matrix that uses the zero matrix (matrix of all zeros), hence why it is commonly referred to as simply the zero matrix.
    \begin{itemize}
      \item Multiplication by the zero matrix of course does not yield the original matrix (unless the original matrix was a zero matrix), but the addition of zero will yield the original product, i.e.,
      \[%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \bm{M0} = \bm{0M}\neq M ,\qquad  \bm{M} + \bm{0} = \bm{M} 
      \]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \end{itemize}
  \end{itemize}
  
  \subsection{Creating Symmetric Matrices}\label{Creating Symmetric Matrices}
  \begin{itemize}
    \item 
  \end{itemize}
  
  \subsection{Hadamard Multiplication}\label{Hadamard Multiplication}
  \begin{itemize}
    \item 
  \end{itemize}
  
  \subsection{Multiplication of Symmetric Matrices}\label{Multiplication of Symmetric Matrices}
  \begin{itemize}
    \item 
  \end{itemize}

  \subsection{Frobenius Dot Product}\label{Frobenius Dot Product}
  \begin{itemize}
    \item 
  \end{itemize}
  
  \subsection{Matrix Norms}\label{Other Matrix Norms}
  \begin{itemize}
    \item 
  \end{itemize}
\end{itemize}